{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KPEBW1spC7-KlounT6wSvHvrmulCH5yK",
      "authorship_tag": "ABX9TyMwORH1+paIabv7f3sCWXgW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurralamanoj/Data-Science-For-Beginners/blob/main/Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Practice\n",
        "\n",
        "What we are doing here.\n",
        "\n",
        "*   Loading the Data\n",
        "*   Visualize the Images\n",
        "*   Separate the labels and Pixels\n",
        "*   Divide the train and test data\n",
        "*   Implement the model using SKlearn\n",
        "*   Implement the model using Keras\n",
        "*   Conclusion\n",
        "*   List item\n",
        "\n",
        "\n",
        "##About Dataset\n",
        "\n",
        "###Context\n",
        "\n",
        "Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
        "\n",
        "The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\"\n",
        "\n",
        "Zalando seeks to replace the original MNIST dataset\n",
        "\n",
        "###Content\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
        "\n",
        "To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.\n",
        "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.\n",
        "\n",
        "\n",
        "###Labels\n",
        "\n",
        "Each training and test example is assigned to one of the following labels:\n",
        "\n",
        "0 T-shirt/top\n",
        "1 Trouser\n",
        "2 Pullover\n",
        "3 Dress\n",
        "4 Coat\n",
        "5 Sandal\n",
        "6 Shirt\n",
        "7 Sneaker\n",
        "8 Bag\n",
        "9 Ankle boot\n",
        "\n",
        "\n",
        "###TL;DR\n",
        "\n",
        "Each row is a separate image\n",
        "Column 1 is the class label.\n",
        "Remaining columns are pixel numbers (784 total).\n",
        "Each value is the darkness of the pixel (1 to 255)\n",
        "\n",
        "###Acknowledgements\n",
        "\n",
        "Original dataset was downloaded from https://github.com/zalandoresearch/fashion-mnist\n",
        "\n",
        "Dataset was converted to CSV with this script: https://pjreddie.com/projects/mnist-in-csv/\n",
        "\n",
        "###License\n",
        "\n",
        "The MIT License (MIT) Copyright © [2017] Zalando SE, https://tech.zalando.com\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YMt4om1WITHZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXmSfUxvF2P6",
        "outputId": "8a5a975c-9daf-43d6-9bc0-1affd74dc08b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fashionmnist.zip to /content\n",
            " 89% 61.0M/68.8M [00:00<00:00, 183MB/s]\n",
            "100% 68.8M/68.8M [00:00<00:00, 165MB/s]\n",
            "Archive:  /content/fashionmnist.zip\n",
            "  inflating: fashion-mnist_test.csv  \n",
            "  inflating: fashion-mnist_train.csv  \n",
            "  inflating: t10k-images-idx3-ubyte  \n",
            "  inflating: t10k-labels-idx1-ubyte  \n",
            "  inflating: train-images-idx3-ubyte  \n",
            "  inflating: train-labels-idx1-ubyte  \n"
          ]
        }
      ],
      "source": [
        "#! pip install kaggle\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json  \n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d zalando-research/fashionmnist\n",
        "! unzip '/content/fashionmnist.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, classification_report, plot_confusion_matrix, ConfusionMatrixDisplay, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "H6Q4IF-PPd28"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('fashion-mnist_train.csv')\n",
        "test = pd.read_csv('fashion-mnist_test.csv')"
      ],
      "metadata": {
        "id": "rF2gJrQEQ7cX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "6WGJW-YXROWm",
        "outputId": "7b9af4b9-1a70-421f-f2f5-6ad449c275d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0          2       0       0       0       0       0       0       0       0   \n",
              "1          9       0       0       0       0       0       0       0       0   \n",
              "2          6       0       0       0       0       0       0       0       5   \n",
              "3          0       0       0       0       1       2       0       0       0   \n",
              "4          3       0       0       0       0       0       0       0       0   \n",
              "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "59995      9       0       0       0       0       0       0       0       0   \n",
              "59996      1       0       0       0       0       0       0       0       0   \n",
              "59997      8       0       0       0       0       0       0       0       0   \n",
              "59998      8       0       0       0       0       0       0       0       0   \n",
              "59999      7       0       0       0       0       0       0       0       0   \n",
              "\n",
              "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
              "0           0  ...         0         0         0         0         0   \n",
              "1           0  ...         0         0         0         0         0   \n",
              "2           0  ...         0         0         0        30        43   \n",
              "3           0  ...         3         0         0         0         0   \n",
              "4           0  ...         0         0         0         0         0   \n",
              "...       ...  ...       ...       ...       ...       ...       ...   \n",
              "59995       0  ...         0         0         0         0         0   \n",
              "59996       0  ...        73         0         0         0         0   \n",
              "59997       0  ...       160       162       163       135        94   \n",
              "59998       0  ...         0         0         0         0         0   \n",
              "59999       0  ...         0         0         0         0         0   \n",
              "\n",
              "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
              "0             0         0         0         0         0  \n",
              "1             0         0         0         0         0  \n",
              "2             0         0         0         0         0  \n",
              "3             1         0         0         0         0  \n",
              "4             0         0         0         0         0  \n",
              "...         ...       ...       ...       ...       ...  \n",
              "59995         0         0         0         0         0  \n",
              "59996         0         0         0         0         0  \n",
              "59997         0         0         0         0         0  \n",
              "59998         0         0         0         0         0  \n",
              "59999         0         0         0         0         0  \n",
              "\n",
              "[60000 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2e07a5a-fb23-48b5-8b00-74195bde82b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>160</td>\n",
              "      <td>162</td>\n",
              "      <td>163</td>\n",
              "      <td>135</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2e07a5a-fb23-48b5-8b00-74195bde82b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2e07a5a-fb23-48b5-8b00-74195bde82b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2e07a5a-fb23-48b5-8b00-74195bde82b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "b49aYYtuRQMd",
        "outputId": "aaaef5e8-b0ce-41df-d909-5c2693b1f889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0         0       0       0       0       0       0       0       0       9   \n",
              "1         1       0       0       0       0       0       0       0       0   \n",
              "2         2       0       0       0       0       0       0      14      53   \n",
              "3         2       0       0       0       0       0       0       0       0   \n",
              "4         3       0       0       0       0       0       0       0       0   \n",
              "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "9995      0       0       0       0       0       0       0       0       0   \n",
              "9996      6       0       0       0       0       0       0       0       0   \n",
              "9997      8       0       0       0       0       0       0       0       0   \n",
              "9998      8       0       1       3       0       0       0       0       0   \n",
              "9999      1       0       0       0       0       0       0       0     140   \n",
              "\n",
              "      pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0          8  ...       103        87        56         0         0         0   \n",
              "1          0  ...        34         0         0         0         0         0   \n",
              "2         99  ...         0         0         0         0        63        53   \n",
              "3          0  ...       137       126       140         0       133       224   \n",
              "4          0  ...         0         0         0         0         0         0   \n",
              "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
              "9995       0  ...        32        23        14        20         0         0   \n",
              "9996       0  ...         0         0         0         2        52        23   \n",
              "9997       0  ...       175       172       172       182       199       222   \n",
              "9998       0  ...         0         0         0         0         0         1   \n",
              "9999     119  ...       111        95        75        44         1         0   \n",
              "\n",
              "      pixel781  pixel782  pixel783  pixel784  \n",
              "0            0         0         0         0  \n",
              "1            0         0         0         0  \n",
              "2           31         0         0         0  \n",
              "3          222        56         0         0  \n",
              "4            0         0         0         0  \n",
              "...        ...       ...       ...       ...  \n",
              "9995         1         0         0         0  \n",
              "9996        28         0         0         0  \n",
              "9997        42         0         1         0  \n",
              "9998         0         0         0         0  \n",
              "9999         0         0         0         0  \n",
              "\n",
              "[10000 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af109fbd-9015-4201-9171-6d6653799bf3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>103</td>\n",
              "      <td>87</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>99</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>53</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>137</td>\n",
              "      <td>126</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>175</td>\n",
              "      <td>172</td>\n",
              "      <td>172</td>\n",
              "      <td>182</td>\n",
              "      <td>199</td>\n",
              "      <td>222</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>119</td>\n",
              "      <td>...</td>\n",
              "      <td>111</td>\n",
              "      <td>95</td>\n",
              "      <td>75</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af109fbd-9015-4201-9171-6d6653799bf3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af109fbd-9015-4201-9171-6d6653799bf3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af109fbd-9015-4201-9171-6d6653799bf3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcPy8W7E3eE1",
        "outputId": "57e44022-0a5e-4518-ea6e-1aec09491c8d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 785)\n",
            "(10000, 785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = [\"pixel{}\".format(pixel_num) for pixel_num in range(1,785)]\n",
        "rows_to_examine = 2\n",
        "image_data = np.reshape(train[features][rows_to_examine:rows_to_examine+1].to_numpy(),(28,28))\n",
        "print(image_data.shape)\n",
        "plt.imshow(image_data,cmap=\"gray\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "nP0eudGz8aQ9",
        "outputId": "0ffa9d73-390a-429d-d707-d9b4a2d69ab5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff3a7980890>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rows_to_examine = 1\n",
        "image_data = np.reshape(train[features][rows_to_examine:rows_to_examine+1].to_numpy(),(28,28))\n",
        "print(image_data.shape)\n",
        "plt.imshow(image_data,cmap=\"gray\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Pr7ILP4iCZH4",
        "outputId": "8a2f8f4c-66d2-4725-9909-3def8dc989e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff3a79593d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQ3UlEQVR4nO3de4xUZZrH8d8joCAXAUEgwi4zI6holDEEV9d4CXF0iYnwz2T8Y+O6E5kYTdSYrGQ2Zkw2JmZ3Z/cPjZMwGTO4zjoZI+4YXVeF4LDeJrSI3HREuSgI3Vy8gAJC8+wffdi02ud52zpVdWp8v5+k09319Kl6qe4f51Q95z2vubsAfPudVPcAALQHYQcyQdiBTBB2IBOEHcjE0HY+mJnx1j/QYu5uA91eac9uZtea2Z/M7F0zW1zlvgC0ljXaZzezIZLekXS1pB2SVku6wd03BduwZwdarBV79rmS3nX3Le7+haTfSrq+wv0BaKEqYT9T0gf9vt9R3PYlZrbIzLrMrKvCYwGoqOVv0Ln7EklLJA7jgTpV2bPvlDSt3/dTi9sAdKAqYV8taYaZfcfMTpb0I0lPNWdYAJqt4cN4dz9mZrdJek7SEEkPu/vGpo0MQFM13Hpr6MF4zQ60XEtOqgHw54OwA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZKLhJZvx58FswAU9B62dq/x+1cKFC8P6Sy+9FNb37NlTWks9L6l/d9Xt61Ap7Ga2TdIBSb2Sjrn7nGYMCkDzNWPPfpW7723C/QBoIV6zA5moGnaX9LyZvW5miwb6ATNbZGZdZtZV8bEAVFD1MP4yd99pZmdIesHM3nb3Vf1/wN2XSFoiSWbWee9aAJmotGd3953F5x5JT0qa24xBAWi+hsNuZiPNbPSJryX9QNKGZg0MQHNVOYyfJOnJot84VNJ/uvv/NGVU+Eainm8n9ntPGDNmTFi/++67w/rWrVvDetRnr/q8dPLzWqbhsLv7FkkXNnEsAFqI1huQCcIOZIKwA5kg7EAmCDuQCWtnCyHXM+hOOin+P7WVv4NOnqr5yCOPhPUzzjgjrO/bty+s33777aW1vXvjuVtVpwanfufR/ff29obbpn4n7j7gnbNnBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE1xKug2OHz/e0vuPerapfm9qbFW3X7x4cWlt4sSJ4bbvv/9+WJ8zJ76Y8ahRo0prqT770KHVonH06NFK27cCe3YgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJBn/1bIOqzp/rgQ4YMCeupudXXXXddWL/11ltLa08//XS47cGDB8P62rVrw/q2bdvCeqTVffKrrrqqtLZp06Zw2+7u7oYekz07kAnCDmSCsAOZIOxAJgg7kAnCDmSCsAOZoM/eBlWvzZ7avsp8+VQf/eKLLw7rDz74YFhfuXJlae3w4cPhtvv37w/rUa9aiuesP/roo+G29913X1hPzaUfO3ZsWL/55ptLa/Pnzw+3bVRyz25mD5tZj5lt6HfbeDN7wcw2F5/HtWR0AJpmMIfxv5Z07VduWyxphbvPkLSi+B5AB0uG3d1XSfrq8dT1kpYWXy+VtKDJ4wLQZI2+Zp/k7ruKr3dLmlT2g2a2SNKiBh8HQJNUfoPO3T1asNHdl0haIuW7sCPQCRptvXWb2RRJKj73NG9IAFqh0bA/JenG4usbJf2+OcMB0CrJ9dnN7DFJV0qaIKlb0s8k/Zek30n6C0nbJf3Q3eOmqDiML1PnGumzZs0K688991xYX7FiRVg/cOBAaa2nJz4gPOecc8L6pZdeGtY/+eST0tro0aPDbadMmRLW33vvvbC+efPmsB7NSb/lllvCbVPK1mdPvmZ39xtKSvMqjQhAW3G6LJAJwg5kgrADmSDsQCYIO5CJb80U11T7KrX0cGqqZ3T/qdZY1cs1jxgxIqwfOnSotDZpUumZzJKk5cuXh/VVq1aF9ai1Jkk7duworZ1//vnhtpdffnlY37NnT1j/4osvSmup6bNR205KL/mcas1Nnz69tJZqOb799tthvQx7diAThB3IBGEHMkHYgUwQdiAThB3IBGEHMvGt6bOnet2pXnbV+69i6ND41xD10aX4ssXPP/98uO369evD+gcffBDWU73uK664orR2wQUXhNumeuGpS2ifeuqppbXU7/P0008P62+88UZYTy03Hd3/NddcE25Lnx1AiLADmSDsQCYIO5AJwg5kgrADmSDsQCba3meP5oWn5pxHvdFU37TKfUvxuFM9/Ko9/nnz4gv5PvDAA6W1nTt3htuuW7curEfz0SVpwYJ4mb+ZM2eW1j788MNw22HDhoX11PkJ0Zz0qVOnhtumLgX96quvhvXU/Ufz3VPXZmgUe3YgE4QdyARhBzJB2IFMEHYgE4QdyARhBzKRXLK5qQ+W6ZLNs2fPDut33nlnWL/kkkvC+ptvvlla2717d7jt9u3bw/rVV18d1i+66KKwvmXLltLa8OHDw22j675L6X50NM8/Nd982bJlYf2UU04J69OmTQvr0dgnT54cbpv6nZQt2Zzcs5vZw2bWY2Yb+t12r5ntNLO1xcf81P0AqNdgDuN/LenaAW7/d3efXXz8d3OHBaDZkmF391WS4usDAeh4Vd6gu83M1hWH+ePKfsjMFplZl5l1VXgsABU1GvZfSPqepNmSdkn6edkPuvsSd5/j7nMafCwATdBQ2N2929173f24pF9KmtvcYQFotobCbmZT+n27UNKGsp8F0BmS89nN7DFJV0qaYGY7JP1M0pVmNluSS9om6SfNGMyoUaPCejR/+ciRI+G2R48eDeunnXZaWJ87t/zg5aabbgq3Pffcc8N6d3d3WH/22WfDemped2TChAlhfcaMGWH9o48+Cusnn3xyaS11jkfq7yG1bn10DsHq1avDbVPPS9TDl9LnCLzzzjultdT67GeddVZpLbrOf/KvxN1vGODmX6W2A9BZOF0WyARhBzJB2IFMEHYgE4QdyERbLyU9YsSI8NLCa9euDbdfsWJFaS3Vxkm13iZOnBjWhwwZUlpLTSN98cUXw3qqbZiaTplaurjKths3bgzrZ599dlgfM2ZMaS3VMkwtB/3yyy+H9Z6entJa6jLVqeclum8p3ZKM/m3R35oUt/WiHLBnBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE23tsw8fPjyc7tnVFV+5ateuXaW1VM821btM9XQ//fTTsB5JTcVMTeVMTZeMequpf3eqvn79+rCe6sOPG1d6xTIdPnw43PbQoUNhPTUtObqcc6rPnlri+9ixY2F99OjRYT06dyL1+967d29D42LPDmSCsAOZIOxAJgg7kAnCDmSCsAOZIOxAJto+n/28884rraf6rgcOHCitpeYPp+Ynjxw5MqyPHz++tBZdLllK92RT/eTUXP1o+d/UY6fOT0gtPfzxxx+H9Wjs0XMqSbNmzQrrqXMEouWiU8s9Vz0/IdWn7+3tLa2lrr0Q/b0wnx0AYQdyQdiBTBB2IBOEHcgEYQcyQdiBTLS1zz5s2DBNnjy5tD59+vRw+6h3Gc11l+KeqyTt27cvrKfmu0dSc6dTPdtUHz/qlaceO7qu+2DqqT78hRdeWFpL9fhXrlwZ1lPnTkTXEUidf5B6zlPnhFT5e4l68FL6vIsyyT27mU0zs5VmtsnMNprZ7cXt483sBTPbXHwuv0oBgNoN5jD+mKS73H2WpL+SdKuZzZK0WNIKd58haUXxPYAOlQy7u+9y9zXF1wckvSXpTEnXS1pa/NhSSQtaNUgA1X2jN+jMbLqk70v6o6RJ7n7ihfJuSZNKtllkZl1m1hWd2w6gtQYddjMbJekJSXe4+5euvuh97xgM+K6Buy9x9znuPid1ET4ArTOosJvZMPUF/Tfuvqy4udvMphT1KZLiZS0B1MoGMX3S1PeafL+739Hv9n+RtM/d7zezxZLGu/s/JO4rfLAFC+KX/XfddVdpLdXGSV2uOdXGiVpzqctMpy4NPHz48LCeap9FLabUvzsl9by88sorYf3xxx8vrb322mvhtqkW1Lx588L6Qw89VFrbunVruG3q7+nzzz8P6wcPHgzr0d/E1KlTw20XLlxYWvvss8/U29s74PzdwfTZ/1rS30pab2YnFlD/qaT7Jf3OzH4sabukHw7ivgDUJBl2d39JUtlM//i/VgAdg9NlgUwQdiAThB3IBGEHMkHYgUwk++xNfbBEn72K1DTR2bNnh/W5c+eG9fnz55fWZs6cGW6bumRyarpkavrtkSNHSmvLly8Pt33mmWfCeqqPXqexY8eG9ajHHy2ZLKX76KlLUae2j6bQrlmzJtz2nnvuCevuPuDg2LMDmSDsQCYIO5AJwg5kgrADmSDsQCYIO5CJjuqzp3rlqfnNaL/UXPsqUksXY2D02YHMEXYgE4QdyARhBzJB2IFMEHYgE4QdyERH9dkBVEefHcgcYQcyQdiBTBB2IBOEHcgEYQcyQdiBTCTDbmbTzGylmW0ys41mdntx+71mttPM1hYf5RdWB1C75Ek1ZjZF0hR3X2NmoyW9LmmB+tZjP+ju/zroB+OkGqDlyk6qGcz67Lsk7Sq+PmBmb0k6s7nDA9Bq3+g1u5lNl/R9SX8sbrrNzNaZ2cNmNq5km0Vm1mVmXZVGCqCSQZ8bb2ajJP1B0n3uvszMJknaK8kl/ZP6DvX/PnEfHMYDLVZ2GD+osJvZMElPS3rO3f9tgPp0SU+7+/mJ+yHsQIs1PBHG+par/JWkt/oHvXjj7oSFkjZUHSSA1hnMu/GXSfpfSeslHS9u/qmkGyTNVt9h/DZJPynezIvuiz070GKVDuObhbADrcd8diBzhB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IRPKCk022V9L2ft9PKG7rRJ06tk4dl8TYGtXMsf1lWaGt89m/9uBmXe4+p7YBBDp1bJ06LomxNapdY+MwHsgEYQcyUXfYl9T8+JFOHVunjktibI1qy9hqfc0OoH3q3rMDaBPCDmSilrCb2bVm9icze9fMFtcxhjJmts3M1hfLUNe6Pl2xhl6PmW3od9t4M3vBzDYXnwdcY6+msXXEMt7BMuO1Pnd1L3/e9tfsZjZE0juSrpa0Q9JqSTe4+6a2DqSEmW2TNMfdaz8Bw8wul3RQ0iMnltYys3+WtN/d7y/+oxzn7nd3yNju1TdcxrtFYytbZvzvVONz18zlzxtRx559rqR33X2Lu38h6beSrq9hHB3P3VdJ2v+Vm6+XtLT4eqn6/ljarmRsHcHdd7n7muLrA5JOLDNe63MXjKst6gj7mZI+6Pf9DnXWeu8u6Xkze93MFtU9mAFM6rfM1m5Jk+oczACSy3i301eWGe+Y566R5c+r4g26r7vM3S+S9DeSbi0OVzuS970G66Te6S8kfU99awDukvTzOgdTLDP+hKQ73P3T/rU6n7sBxtWW562OsO+UNK3f91OL2zqCu+8sPvdIelJ9Lzs6SfeJFXSLzz01j+f/uXu3u/e6+3FJv1SNz12xzPgTkn7j7suKm2t/7gYaV7uetzrCvlrSDDP7jpmdLOlHkp6qYRxfY2YjizdOZGYjJf1AnbcU9VOSbiy+vlHS72scy5d0yjLeZcuMq+bnrvblz9297R+S5qvvHfn3JP1jHWMoGdd3Jb1ZfGyse2ySHlPfYd1R9b238WNJp0taIWmzpOWSxnfQ2P5DfUt7r1NfsKbUNLbL1HeIvk7S2uJjft3PXTCutjxvnC4LZII36IBMEHYgE4QdyARhBzJB2IFMEHYgE4QdyMT/AeEB0qsdB4hgAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train.iloc[:,1:]\n",
        "y = train['label']\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6YS0t43BKv0",
        "outputId": "085c40ba-b350-4fcf-df48-68bafb4e1808"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 184)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpk4K389FVEZ",
        "outputId": "fc6cb270-5b6a-4102-98f6-825d30c23669"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n",
            "(48000,)\n",
            "(12000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IFG-nFP7Nb9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation using sklearn (MLPClassifier)"
      ],
      "metadata": {
        "id": "N87QrnCMNQHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(16,16,16), activation=\"relu\", max_iter=200, verbose=True)"
      ],
      "metadata": {
        "id": "vvaDhdtuIj8i"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yim5m6CLJLAk",
        "outputId": "bbfbecc4-a599-47d2-8a3b-15b67c7d50e7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 2.90240636\n",
            "Iteration 2, loss = 2.30849893\n",
            "Iteration 3, loss = 2.29875388\n",
            "Iteration 4, loss = 2.08635543\n",
            "Iteration 5, loss = 1.71075072\n",
            "Iteration 6, loss = 1.50786654\n",
            "Iteration 7, loss = 1.35542779\n",
            "Iteration 8, loss = 1.23046535\n",
            "Iteration 9, loss = 1.07035526\n",
            "Iteration 10, loss = 1.02740200\n",
            "Iteration 11, loss = 0.87620577\n",
            "Iteration 12, loss = 0.83161584\n",
            "Iteration 13, loss = 0.79304123\n",
            "Iteration 14, loss = 0.77352915\n",
            "Iteration 15, loss = 0.74734775\n",
            "Iteration 16, loss = 0.72584650\n",
            "Iteration 17, loss = 0.70159178\n",
            "Iteration 18, loss = 0.70015412\n",
            "Iteration 19, loss = 0.68412704\n",
            "Iteration 20, loss = 0.67776077\n",
            "Iteration 21, loss = 0.67039475\n",
            "Iteration 22, loss = 0.66716914\n",
            "Iteration 23, loss = 0.67091276\n",
            "Iteration 24, loss = 0.65801895\n",
            "Iteration 25, loss = 0.66185855\n",
            "Iteration 26, loss = 0.64663842\n",
            "Iteration 27, loss = 0.65238597\n",
            "Iteration 28, loss = 0.64932489\n",
            "Iteration 29, loss = 0.64120601\n",
            "Iteration 30, loss = 0.64432471\n",
            "Iteration 31, loss = 0.63778749\n",
            "Iteration 32, loss = 0.63749525\n",
            "Iteration 33, loss = 0.63856929\n",
            "Iteration 34, loss = 0.63018214\n",
            "Iteration 35, loss = 0.62963508\n",
            "Iteration 36, loss = 0.61841797\n",
            "Iteration 37, loss = 0.60564713\n",
            "Iteration 38, loss = 0.60430723\n",
            "Iteration 39, loss = 0.60528862\n",
            "Iteration 40, loss = 0.59486116\n",
            "Iteration 41, loss = 0.59181944\n",
            "Iteration 42, loss = 0.58808823\n",
            "Iteration 43, loss = 0.57657796\n",
            "Iteration 44, loss = 0.58862699\n",
            "Iteration 45, loss = 0.57815772\n",
            "Iteration 46, loss = 0.57390299\n",
            "Iteration 47, loss = 0.56503405\n",
            "Iteration 48, loss = 0.57131424\n",
            "Iteration 49, loss = 0.56239491\n",
            "Iteration 50, loss = 0.56392635\n",
            "Iteration 51, loss = 0.55761474\n",
            "Iteration 52, loss = 0.55646523\n",
            "Iteration 53, loss = 0.55468652\n",
            "Iteration 54, loss = 0.55765506\n",
            "Iteration 55, loss = 0.55462721\n",
            "Iteration 56, loss = 0.55919802\n",
            "Iteration 57, loss = 0.55726191\n",
            "Iteration 58, loss = 0.55232708\n",
            "Iteration 59, loss = 0.55151565\n",
            "Iteration 60, loss = 0.54162090\n",
            "Iteration 61, loss = 0.54011307\n",
            "Iteration 62, loss = 0.54940642\n",
            "Iteration 63, loss = 0.54991837\n",
            "Iteration 64, loss = 0.53956978\n",
            "Iteration 65, loss = 0.54635466\n",
            "Iteration 66, loss = 0.54294218\n",
            "Iteration 67, loss = 0.54512958\n",
            "Iteration 68, loss = 0.54481249\n",
            "Iteration 69, loss = 0.54447221\n",
            "Iteration 70, loss = 0.54472534\n",
            "Iteration 71, loss = 0.53887449\n",
            "Iteration 72, loss = 0.54216882\n",
            "Iteration 73, loss = 0.53944874\n",
            "Iteration 74, loss = 0.53523841\n",
            "Iteration 75, loss = 0.53784312\n",
            "Iteration 76, loss = 0.52860609\n",
            "Iteration 77, loss = 0.53573910\n",
            "Iteration 78, loss = 0.53555917\n",
            "Iteration 79, loss = 0.53573746\n",
            "Iteration 80, loss = 0.53988435\n",
            "Iteration 81, loss = 0.53766685\n",
            "Iteration 82, loss = 0.54310315\n",
            "Iteration 83, loss = 0.53615369\n",
            "Iteration 84, loss = 0.52937778\n",
            "Iteration 85, loss = 0.52713511\n",
            "Iteration 86, loss = 0.52594361\n",
            "Iteration 87, loss = 0.53618742\n",
            "Iteration 88, loss = 0.53503803\n",
            "Iteration 89, loss = 0.52785035\n",
            "Iteration 90, loss = 0.52826434\n",
            "Iteration 91, loss = 0.52742248\n",
            "Iteration 92, loss = 0.54071507\n",
            "Iteration 93, loss = 0.53455263\n",
            "Iteration 94, loss = 0.52874564\n",
            "Iteration 95, loss = 0.52849202\n",
            "Iteration 96, loss = 0.53379420\n",
            "Iteration 97, loss = 0.52390310\n",
            "Iteration 98, loss = 0.53001037\n",
            "Iteration 99, loss = 0.52745463\n",
            "Iteration 100, loss = 0.53027416\n",
            "Iteration 101, loss = 0.51902362\n",
            "Iteration 102, loss = 0.52452901\n",
            "Iteration 103, loss = 0.52171422\n",
            "Iteration 104, loss = 0.52056470\n",
            "Iteration 105, loss = 0.52403189\n",
            "Iteration 106, loss = 0.52252790\n",
            "Iteration 107, loss = 0.52226055\n",
            "Iteration 108, loss = 0.52343799\n",
            "Iteration 109, loss = 0.52894509\n",
            "Iteration 110, loss = 0.53026664\n",
            "Iteration 111, loss = 0.51735687\n",
            "Iteration 112, loss = 0.52379092\n",
            "Iteration 113, loss = 0.52760250\n",
            "Iteration 114, loss = 0.52115539\n",
            "Iteration 115, loss = 0.51851242\n",
            "Iteration 116, loss = 0.52288276\n",
            "Iteration 117, loss = 0.51444991\n",
            "Iteration 118, loss = 0.52395379\n",
            "Iteration 119, loss = 0.51011811\n",
            "Iteration 120, loss = 0.51029967\n",
            "Iteration 121, loss = 0.52804921\n",
            "Iteration 122, loss = 0.51727328\n",
            "Iteration 123, loss = 0.51229727\n",
            "Iteration 124, loss = 0.52554139\n",
            "Iteration 125, loss = 0.52110528\n",
            "Iteration 126, loss = 0.50893335\n",
            "Iteration 127, loss = 0.51403978\n",
            "Iteration 128, loss = 0.51765874\n",
            "Iteration 129, loss = 0.51423006\n",
            "Iteration 130, loss = 0.51649938\n",
            "Iteration 131, loss = 0.52108416\n",
            "Iteration 132, loss = 0.52406581\n",
            "Iteration 133, loss = 0.51124680\n",
            "Iteration 134, loss = 0.51496347\n",
            "Iteration 135, loss = 0.51392299\n",
            "Iteration 136, loss = 0.52161908\n",
            "Iteration 137, loss = 0.51519552\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(16, 16, 16), verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.coefs_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ITiSu3kMsSz",
        "outputId": "9650b8aa-2e4f-444f-b907-d295621a0541"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 2.02643004e-001, -2.51935362e-315,  4.75957459e-315, ...,\n",
              "          1.08046097e-315,  1.84751064e-315,  4.24522783e-315],\n",
              "        [ 3.30125687e-001, -4.47163100e-315,  1.83149537e-001, ...,\n",
              "         -6.15939447e-316, -1.92868944e-315,  2.28676293e-001],\n",
              "        [-1.19614284e+000, -2.62393259e-315,  1.93194442e-001, ...,\n",
              "         -1.66835926e-315,  2.34491543e-315,  2.28695462e-001],\n",
              "        ...,\n",
              "        [ 1.55483092e-001,  1.28629472e-138,  1.79735216e-002, ...,\n",
              "         -1.01189595e-280,  1.35977164e-162, -6.68567379e-002],\n",
              "        [ 2.54867327e-001,  1.46205218e-157, -7.26902324e-001, ...,\n",
              "         -7.92059878e-316,  6.33285655e-228, -3.16384142e-001],\n",
              "        [ 2.72993827e-001,  4.22654535e-315,  3.35052550e-001, ...,\n",
              "         -4.34574584e-315, -2.92236707e-316,  1.09788680e-002]]),\n",
              " array([[-8.48609297e-002, -1.18080230e-001,  2.30807212e-002,\n",
              "          1.04969293e-001,  1.03522584e-001,  1.90185592e-001,\n",
              "         -9.58742557e-002,  1.26950343e-001, -5.79368968e-003,\n",
              "          1.08360085e-001, -2.65991547e-002, -2.05146505e-001,\n",
              "         -3.47532574e-001, -1.80477671e-001,  2.06646834e-002,\n",
              "          5.81774719e-002],\n",
              "        [ 9.28993369e-010, -1.17867887e-036,  1.62400577e-040,\n",
              "         -2.49837581e-144,  2.98542952e-195,  1.97271785e-012,\n",
              "          1.36698238e-237, -2.54735327e-012,  4.81457560e-133,\n",
              "          1.81120583e-195,  4.03560788e-116,  1.14238845e-216,\n",
              "          1.23825448e-015, -3.38636934e-087, -2.57315383e-178,\n",
              "          8.32843556e-043],\n",
              "        [-1.00763631e+000, -1.74492952e-001,  1.28422067e-001,\n",
              "          5.16352772e-003, -1.30676064e-001, -1.20331212e-002,\n",
              "          1.39658155e-001, -2.60057367e-003,  6.51714989e-003,\n",
              "         -8.87823264e-002, -5.52120520e-002, -7.38810329e-002,\n",
              "          4.57702623e-002, -1.13381937e-001,  3.54966789e-002,\n",
              "          3.16791656e-002],\n",
              "        [-6.72941316e-005,  2.63937552e-001,  2.17267107e-001,\n",
              "         -3.67125055e-002, -4.01128855e-002,  3.09963703e-001,\n",
              "          7.05311228e-003,  2.27716897e-001, -8.74356673e-002,\n",
              "         -5.52902046e-002,  1.64745999e-001,  1.37261491e-181,\n",
              "         -3.30567033e-002,  3.23982674e-001, -1.95054260e-002,\n",
              "          3.66060045e-001],\n",
              "        [-3.20624075e-037, -6.11076755e-027,  2.27398198e-002,\n",
              "          1.29419868e-001,  4.43391596e-002,  2.40707035e-001,\n",
              "          5.83415378e-128,  1.07003872e-001,  6.20340368e-002,\n",
              "          9.65784622e-003,  6.93485241e-022,  7.20413376e-165,\n",
              "          1.05553023e-076, -1.65913284e-012,  4.02485752e-002,\n",
              "          1.19815590e-001],\n",
              "        [-1.29083908e+000, -3.80569721e-001, -5.80203786e-003,\n",
              "         -1.55196429e-001, -1.16433467e-002, -3.23477275e-003,\n",
              "         -1.99131486e-001,  3.57270090e-002,  3.44160867e-002,\n",
              "          1.17156651e-001,  4.54553563e-002, -4.53513388e-001,\n",
              "         -1.29922510e-001, -6.61539055e-002, -6.51152304e-002,\n",
              "          4.76229399e-002],\n",
              "        [ 4.19188426e-083,  1.30060370e-135,  7.07480185e-035,\n",
              "          4.07391949e-123, -2.65640884e-004, -3.05735756e-002,\n",
              "         -9.66669880e-164, -5.30300059e-002, -2.08829489e-006,\n",
              "          6.64917105e-003,  1.00913227e-002,  2.59695863e-184,\n",
              "         -6.75192936e-092,  1.51293966e-002, -2.03796557e-002,\n",
              "          1.28216753e-004],\n",
              "        [-2.24786380e-082,  2.33091675e-034,  3.00982775e-040,\n",
              "         -1.90840604e-163,  2.22915297e-070,  1.23356282e-024,\n",
              "          2.97242175e-192, -6.26559010e-038, -4.59914667e-040,\n",
              "          1.12516102e-025, -1.70685455e-051, -5.93227911e-200,\n",
              "         -1.11358646e-146,  1.26461598e-090, -1.33176018e-026,\n",
              "         -3.16806662e-035],\n",
              "        [ 6.32351574e-002,  1.22765694e-001,  1.86893768e-002,\n",
              "          1.20769913e-001,  4.04733962e-001, -2.19266546e-001,\n",
              "         -2.72992207e-001,  2.79511640e-001, -1.99521913e-001,\n",
              "          2.53758542e-002,  6.14176175e-002, -5.08733032e-002,\n",
              "         -6.01390791e-002, -1.27733753e-001,  4.24772903e-001,\n",
              "          5.16368232e-002],\n",
              "        [ 1.00822059e-001,  6.40381436e-003,  1.21422742e-002,\n",
              "         -5.49433085e-019, -5.62164393e-119, -2.49000086e-004,\n",
              "         -8.05630734e-012,  2.28796153e-003, -3.42283052e-010,\n",
              "          3.36159740e-109, -2.06546589e-075,  6.03989726e-154,\n",
              "         -9.60420798e-008, -4.43837606e-026, -5.54998576e-011,\n",
              "         -1.25490383e-007],\n",
              "        [ 1.45396557e-001,  6.04377907e-230, -1.05599422e-002,\n",
              "         -5.43541053e-007,  6.07559285e-002, -1.70425190e-006,\n",
              "          3.15924787e-213, -3.66198090e-005, -3.14297747e-004,\n",
              "         -1.01080677e-002,  3.66544013e-002, -5.57971362e-146,\n",
              "          1.65953340e-001,  4.81339984e-002,  7.14858376e-002,\n",
              "          2.52355877e-002],\n",
              "        [ 1.94263970e-002,  2.04722760e-151,  2.76737977e-002,\n",
              "          1.63441094e-002,  1.51401764e-002, -2.47566074e-002,\n",
              "          6.10538760e-002,  3.70419662e-002,  2.75272311e-002,\n",
              "         -8.67628056e-003, -1.79277092e-002, -2.87417421e-002,\n",
              "         -3.32413139e-002, -3.30499740e-002, -3.57368141e-002,\n",
              "          1.94926023e-002],\n",
              "        [ 1.97811306e-005,  5.58437871e-027, -3.06069829e-015,\n",
              "         -3.95594709e-064,  2.29039461e-160, -2.53046508e-009,\n",
              "         -3.27071745e-126, -1.02113020e-005,  1.11110173e-076,\n",
              "         -2.63603904e-092, -2.30826436e-102,  3.85511685e-111,\n",
              "          7.02994226e-010,  2.76485142e-031, -5.32532419e-123,\n",
              "         -8.01858863e-036],\n",
              "        [-3.68794595e-091, -7.37027278e-099,  1.95416692e-014,\n",
              "          1.95097489e-011, -1.31158233e-245, -7.50119492e-060,\n",
              "         -9.20493863e-093, -6.98914307e-073,  5.93048727e-010,\n",
              "         -4.03363889e-317,  1.63216391e-177,  2.96402964e-230,\n",
              "          1.03863880e-015,  1.31726496e-132, -7.55220085e-016,\n",
              "         -5.79218185e-011],\n",
              "        [ 1.33006350e-011,  5.38426373e-072, -6.23302762e-002,\n",
              "          1.06949623e-201,  3.47331087e-002, -9.48167337e-002,\n",
              "         -6.89325492e-119,  6.59683733e-002,  1.80712708e-002,\n",
              "         -4.13702910e-002,  2.14919534e-002,  1.30339513e-223,\n",
              "         -1.02882367e-028, -4.45661268e-002,  1.17007918e-001,\n",
              "          6.12371686e-002],\n",
              "        [-1.08280886e-001, -6.94577851e-002, -1.57180426e-001,\n",
              "         -1.45581148e-001, -1.01184787e-003, -1.62653878e-001,\n",
              "          1.53296575e-001, -1.35834528e-001, -1.04624651e-001,\n",
              "         -2.50083678e-001, -1.67932731e-002,  2.37646471e-001,\n",
              "         -2.39672581e-001,  3.20109550e-001,  8.78946486e-002,\n",
              "         -2.48282707e-001]]),\n",
              " array([[ 9.96154476e-002,  2.19208763e-001, -1.12963147e-200,\n",
              "         -4.98027686e-159,  3.68925277e-001,  1.84742092e-001,\n",
              "          1.69825466e+000, -3.60667386e-001,  3.89404086e-001,\n",
              "         -6.93811243e-001, -2.00432252e-001,  2.57870076e-002,\n",
              "          7.61920540e-001, -1.06942131e-002, -5.61754463e-002,\n",
              "         -1.63721628e-001],\n",
              "        [-2.12156597e-002, -1.07563930e-001, -5.87036323e-072,\n",
              "         -3.31247717e-002,  3.53600491e-001, -1.42633883e-001,\n",
              "         -3.76727526e-001,  1.31447539e-001, -3.39305228e-002,\n",
              "         -3.10368565e-001,  2.84861439e-003,  2.77678566e-002,\n",
              "         -1.56953519e-001,  4.14578064e-001, -6.73487958e-004,\n",
              "         -1.28443147e-001],\n",
              "        [ 2.78162017e-001, -2.34535193e-001,  1.55898931e-001,\n",
              "          1.39481350e-001,  8.47027809e-002,  2.50632986e-001,\n",
              "         -9.92157583e-001,  1.09735851e-001, -2.08430159e-001,\n",
              "         -1.46652174e-002,  2.58686811e-001, -2.28620750e-001,\n",
              "          6.79734721e-002,  9.08460661e-002,  1.83698616e-001,\n",
              "          7.69318810e-002],\n",
              "        [-5.83880899e-001,  1.67543292e-001, -1.59215993e-001,\n",
              "         -1.13943096e-001, -2.37575545e-001,  4.34702717e-002,\n",
              "          1.90169372e-001, -1.22966637e-001, -2.09530856e-001,\n",
              "         -2.97922346e-002, -1.69351902e-001,  1.03907416e-001,\n",
              "          2.41249912e-001, -8.84461399e-002, -1.10120378e-001,\n",
              "          1.70429059e-001],\n",
              "        [ 4.48723118e-002, -6.27038285e-001, -2.16558810e-001,\n",
              "          1.56508643e-002, -1.30094154e-001,  1.74730928e-001,\n",
              "         -1.67632362e-001,  3.40816801e-002, -1.65431822e-001,\n",
              "         -1.62112786e-001, -8.72578934e-002, -6.66386925e-001,\n",
              "         -2.46278725e-001,  7.85894841e-003, -2.24404509e-001,\n",
              "          3.34720931e-001],\n",
              "        [-3.07991961e-001,  1.15082634e-001, -2.54910842e-008,\n",
              "          2.87854615e-001,  3.45786895e-001, -9.48597402e-003,\n",
              "          5.99732344e-002, -2.91351542e-002, -3.41659566e-001,\n",
              "          2.01732394e-001,  1.45557504e-001, -1.13328126e-001,\n",
              "         -7.29419255e-002,  1.22020231e-001, -6.26797919e-003,\n",
              "         -2.80016083e-001],\n",
              "        [-1.10655637e-001,  6.11441020e-002, -1.30255573e-001,\n",
              "         -3.45272470e-001, -3.63768207e-001, -2.88817792e-002,\n",
              "         -2.47179998e-001, -3.51851016e-001, -7.90185700e-002,\n",
              "         -4.52553862e-001, -1.71868288e-001,  2.33888984e-001,\n",
              "         -2.50373756e-001, -2.00093694e-001,  6.73313282e-003,\n",
              "          6.92312362e-002],\n",
              "        [-7.48376389e-002,  2.60140463e-001, -6.43594471e-001,\n",
              "         -1.71292745e-001,  3.38520826e-002, -7.75290187e-002,\n",
              "         -9.74786777e-002, -1.95377910e-001, -5.10418244e-001,\n",
              "          1.83559461e-001, -2.16245812e-001,  1.33186231e-001,\n",
              "         -3.20693325e-001,  1.64249026e-001,  2.76753490e-001,\n",
              "         -2.63261397e-001],\n",
              "        [-2.37336654e-001, -1.00793150e-001,  1.13425105e-001,\n",
              "         -4.93866792e-001,  1.07765302e-001, -1.35608394e-002,\n",
              "          5.60549115e-002, -3.96768440e-001,  4.43682266e-001,\n",
              "         -4.71321164e-002, -7.29983392e-002,  1.30360454e-001,\n",
              "         -8.79388511e-002,  1.62912841e-001,  5.74133193e-002,\n",
              "         -3.98724601e-001],\n",
              "        [-1.86109744e-001, -1.51523875e-001, -4.23765775e-002,\n",
              "         -3.30224594e-001,  4.75150963e-002,  3.47457363e-001,\n",
              "         -1.07381582e-001,  2.27526141e-001, -6.75355425e-002,\n",
              "          2.06734201e-001,  1.29034386e-001, -5.22409499e-001,\n",
              "          1.53278446e-001,  9.35036973e-002,  6.03464985e-002,\n",
              "          1.51835926e-001],\n",
              "        [ 5.40628553e-002, -2.91669395e-001,  2.46623875e-001,\n",
              "          3.16241874e-001,  1.51725989e-003, -3.41316724e-001,\n",
              "         -2.01757946e-001,  3.24855986e-001, -6.75009894e-002,\n",
              "         -2.39819850e-001, -1.18378507e-001,  4.98537789e-001,\n",
              "         -2.67287603e-001,  3.86162593e-002, -3.60044218e-002,\n",
              "          2.32857499e-001],\n",
              "        [ 3.12297959e-001,  1.59226915e-002,  1.10486870e-001,\n",
              "         -5.52901519e-212,  3.52077765e-002,  1.38851779e-001,\n",
              "         -5.00780953e-002, -1.70227984e-002, -1.09812725e-003,\n",
              "          1.16727696e-001, -1.45535341e-001, -1.53593914e-001,\n",
              "         -6.93944178e-002,  2.18920015e-001,  1.54496690e-001,\n",
              "          1.45644866e-001],\n",
              "        [-1.32212564e-001, -3.81639336e-001,  7.56434470e-002,\n",
              "         -4.70755007e-005,  2.75091102e-002,  3.10150861e-002,\n",
              "         -7.00723424e-001, -2.21492339e-001,  3.94239604e-001,\n",
              "         -5.16429477e-001, -1.91992465e-002,  2.69408652e-001,\n",
              "          2.26299827e-001,  2.84838378e-002, -4.30095074e-001,\n",
              "          8.33772887e-002],\n",
              "        [ 3.73606116e-001,  3.86151062e-002,  4.62816757e-002,\n",
              "          4.70028848e-002,  2.48922190e-001,  3.50213537e-002,\n",
              "          1.07741296e-002, -3.41683631e-003, -7.15265633e-001,\n",
              "          3.04292693e-001, -2.27238339e-001, -5.48227960e-001,\n",
              "         -1.31317362e-001,  2.56812219e-002,  2.74744206e-001,\n",
              "          1.40748936e-001],\n",
              "        [-1.92508753e-002, -1.98663819e-003, -3.65187653e-001,\n",
              "         -5.13455754e-001,  2.79134143e-001, -7.88358925e-003,\n",
              "          1.73278566e-001, -1.80968452e-001,  2.29324892e-001,\n",
              "          3.88587178e-001,  1.31639979e-001,  1.72542189e-001,\n",
              "          4.07295674e-001,  1.42586648e-001,  1.04324793e-001,\n",
              "          1.81572333e-001],\n",
              "        [-1.70162929e-001,  3.42596484e-001, -3.55720922e-001,\n",
              "         -2.16438636e-001, -1.92051411e-001, -4.46089413e-001,\n",
              "          3.35739747e-001,  5.71206276e-003,  4.52355030e-001,\n",
              "         -3.61093268e-001,  2.94209535e-001,  2.82831595e-001,\n",
              "         -9.29265454e-002, -2.25352838e-001, -3.64517202e-001,\n",
              "         -1.34421709e-001]]),\n",
              " array([[ 0.4113016 ,  0.18536034,  0.02510636,  0.27461966,  0.05466647,\n",
              "          0.28754068,  0.17585675,  0.15432285,  0.02453291,  0.17796542],\n",
              "        [ 0.06379814, -0.06268975, -0.64703215, -0.1685759 , -0.00355766,\n",
              "         -0.3007782 , -0.11033918, -0.24462313,  0.07872839,  0.03857313],\n",
              "        [-0.65449565,  0.10791106, -0.92165985, -0.83109151, -0.84906687,\n",
              "          0.0658844 , -0.98426522, -0.37849134, -0.03092168, -0.55262297],\n",
              "        [-0.48216749,  0.21653065, -0.61438203, -0.29696744, -0.33730335,\n",
              "         -0.2200795 , -0.39639155, -0.34073516, -0.24742633, -0.52090581],\n",
              "        [ 0.20439801, -0.13565994, -0.11160813,  0.44030602, -0.26140875,\n",
              "         -0.12151731,  0.04201809, -0.06807797,  0.1855466 ,  0.28736571],\n",
              "        [ 0.05876519,  0.40339752, -0.2354884 , -0.3407126 , -0.33235266,\n",
              "         -0.16655691, -0.1539801 ,  0.01917249, -0.07756532,  0.08031183],\n",
              "        [ 0.58638639,  0.43457612,  0.63664852,  0.11483862,  0.18485881,\n",
              "         -0.15060805,  0.44464977, -0.80596921,  0.34488388, -0.18579926],\n",
              "        [-0.32852843, -0.20480562, -0.10760119, -0.33717143, -0.13758365,\n",
              "         -0.25810526, -0.12305663,  0.12630964, -0.09713773, -0.19275129],\n",
              "        [ 0.53236849,  0.45510079,  0.53865696,  0.49132822,  0.53593818,\n",
              "         -0.26873928,  0.57707501, -0.58758647,  0.06826056, -0.74075646],\n",
              "        [-0.17922956,  0.15822146,  0.01807893, -0.26772595, -0.18032973,\n",
              "          0.39550214, -0.025497  ,  0.34838224, -0.18885795,  0.03090044],\n",
              "        [ 0.05239964,  0.23374317,  0.08549458,  0.25034861,  0.27560828,\n",
              "         -0.23629779,  0.07850038, -0.41980268,  0.15003631, -0.37183171],\n",
              "        [ 0.10628518,  0.2990601 , -0.16011379,  0.15243601, -0.16847576,\n",
              "         -0.77805239, -0.10027289, -0.57636946, -0.08949829, -0.26322601],\n",
              "        [ 0.66558383, -0.0563668 , -0.21871501,  0.36018994, -0.42169381,\n",
              "          0.38657988,  0.46171058, -0.15566392,  0.18291625, -0.31220841],\n",
              "        [ 0.13689125, -0.3668455 , -0.009212  , -0.16644931,  0.23834606,\n",
              "          0.01636833,  0.07337682, -0.06667019,  0.20357057,  0.16642209],\n",
              "        [-0.03831845,  0.17546973,  0.17977295,  0.18117377,  0.08277011,\n",
              "         -0.08309822,  0.0267505 ,  0.06178626,  0.31531821, -0.03865551],\n",
              "        [-0.58988774, -0.33460776, -0.2416128 , -0.37678362,  0.01398998,\n",
              "          0.09378734, -0.3747565 , -0.03382706,  0.01328439, -0.00961826]])]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.intercepts_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R8r_jF7MvZ5",
        "outputId": "f68ef93d-cf60-4ef1-8822-12428563290b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-0.01162505, -0.11143355,  2.77860702,  0.0124218 , -0.11953837,\n",
              "         1.22917308, -0.11072429, -0.02026473,  1.3261541 , -0.07826605,\n",
              "        -0.09653022, -0.10417022, -0.06209244, -0.04412798, -0.03720892,\n",
              "         2.93167286]),\n",
              " array([ 1.37449381e+00, -7.83618435e-04, -1.36532529e+00, -6.80664737e-01,\n",
              "        -1.95536267e+00, -2.96110134e-01, -2.77264016e+00, -3.21466323e-01,\n",
              "        -4.16228181e-01,  1.86538712e-02, -2.45872824e+00, -3.29262586e-01,\n",
              "         1.42153918e+00,  3.91905367e-01,  2.60686170e+00,  3.08438735e+00]),\n",
              " array([ 1.26030778,  1.47604668, -0.54892481, -0.41736448, -1.42196306,\n",
              "        -3.54103972,  2.7862725 ,  1.21776286,  2.04456858,  2.39956585,\n",
              "        -1.04983387, -0.60973311,  2.46317438, -1.60315292, -0.217252  ,\n",
              "        -0.04447079]),\n",
              " array([ 0.30641629, -1.48245575,  1.22635002,  1.34566957, -1.16822568,\n",
              "         0.87671002,  0.74722688,  0.35116392,  0.08029578, -2.24639462])]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = mlp.predict(x_test)"
      ],
      "metadata": {
        "id": "vupNJjEhKHXe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_eval(actual,predicted):\n",
        "  confusion_matrix_val = confusion_matrix(actual,predicted)\n",
        "  accuracy_score_val = accuracy_score(actual,predicted)\n",
        "  classification_report_val = classification_report(actual,predicted)\n",
        "  print(\" Accuracy Score   : \" +  str(accuracy_score_val))\n",
        "  print(\" Confusion Matrix : \")\n",
        "  print(confusion_matrix_val)\n",
        "  print(\" Classification Report : \")\n",
        "  print(classification_report_val)"
      ],
      "metadata": {
        "id": "4fotr7k2KYFe"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_eval(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIDwJrqELB5C",
        "outputId": "aaa54a4e-9447-4952-931b-43d2b12550f0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy Score   : 0.7866666666666666\n",
            " Confusion Matrix : \n",
            "[[1015    1   39   63    6    4   83    1   12    1]\n",
            " [   5 1093   17   72    4    0    6    0    3    0]\n",
            " [  21    0  769   12  307    0   66    0    8    0]\n",
            " [  43   12   34 1032   73    1   44    0    8    0]\n",
            " [   5    0  124   45  969    0   18    0    3    0]\n",
            " [   1    0    1    1    0 1145    0   56    6   25]\n",
            " [ 208    0  430   56  351    1  150    0   27    0]\n",
            " [   0    0    1    0    0   42    0 1113    6   13]\n",
            " [   2    0   18   11   13    2    7    7 1123    2]\n",
            " [   0    0    1    0    0   43    0   86    2 1031]]\n",
            " Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.83      0.80      1225\n",
            "           1       0.99      0.91      0.95      1200\n",
            "           2       0.54      0.65      0.59      1183\n",
            "           3       0.80      0.83      0.81      1247\n",
            "           4       0.56      0.83      0.67      1164\n",
            "           5       0.92      0.93      0.93      1235\n",
            "           6       0.40      0.12      0.19      1223\n",
            "           7       0.88      0.95      0.91      1175\n",
            "           8       0.94      0.95      0.94      1185\n",
            "           9       0.96      0.89      0.92      1163\n",
            "\n",
            "    accuracy                           0.79     12000\n",
            "   macro avg       0.78      0.79      0.77     12000\n",
            "weighted avg       0.78      0.79      0.77     12000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NL9m3Lg8NIgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation using Keras"
      ],
      "metadata": {
        "id": "B4Q6pcsQNKu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, activation = \"relu\" , input_dim = 784))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "# sigmoid is used for binary classification\n",
        "# softmax for multiple classification\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUgVFG80NeQt",
        "outputId": "aa5aba83-4a2d-4fcf-9ab6-9d1aebdb5721"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_transformed = to_categorical(y_train)\n",
        "y_test_transformed = to_categorical(y_test)\n",
        "print(y_train_transformed.shape)\n",
        "print(y_test_transformed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw9OVFKlRjvg",
        "outputId": "b6acbec4-f0f4-447d-bca2-385dbdffdf71"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 10)\n",
            "(12000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "XtvArnrRSrVe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train,y_train_transformed,validation_data = (x_test,y_test_transformed), batch_size = 64, epochs = 200, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vftU3RlvTOjd",
        "outputId": "60c2be0e-bf14-491d-a832-a80643e140d3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "750/750 - 6s - loss: 2.6617 - accuracy: 0.4816 - val_loss: 0.8751 - val_accuracy: 0.7025 - 6s/epoch - 8ms/step\n",
            "Epoch 2/200\n",
            "750/750 - 3s - loss: 0.9671 - accuracy: 0.6683 - val_loss: 0.7279 - val_accuracy: 0.7500 - 3s/epoch - 4ms/step\n",
            "Epoch 3/200\n",
            "750/750 - 3s - loss: 0.7998 - accuracy: 0.7155 - val_loss: 0.6247 - val_accuracy: 0.7700 - 3s/epoch - 4ms/step\n",
            "Epoch 4/200\n",
            "750/750 - 3s - loss: 0.7412 - accuracy: 0.7183 - val_loss: 0.6350 - val_accuracy: 0.7393 - 3s/epoch - 4ms/step\n",
            "Epoch 5/200\n",
            "750/750 - 3s - loss: 0.6992 - accuracy: 0.7408 - val_loss: 0.5809 - val_accuracy: 0.7964 - 3s/epoch - 4ms/step\n",
            "Epoch 6/200\n",
            "750/750 - 3s - loss: 0.6787 - accuracy: 0.7495 - val_loss: 0.5599 - val_accuracy: 0.7869 - 3s/epoch - 4ms/step\n",
            "Epoch 7/200\n",
            "750/750 - 3s - loss: 0.6604 - accuracy: 0.7575 - val_loss: 0.5643 - val_accuracy: 0.7952 - 3s/epoch - 4ms/step\n",
            "Epoch 8/200\n",
            "750/750 - 3s - loss: 0.6371 - accuracy: 0.7634 - val_loss: 0.5369 - val_accuracy: 0.8022 - 3s/epoch - 4ms/step\n",
            "Epoch 9/200\n",
            "750/750 - 3s - loss: 0.6158 - accuracy: 0.7715 - val_loss: 0.5369 - val_accuracy: 0.7968 - 3s/epoch - 4ms/step\n",
            "Epoch 10/200\n",
            "750/750 - 3s - loss: 0.6106 - accuracy: 0.7726 - val_loss: 0.5258 - val_accuracy: 0.8083 - 3s/epoch - 4ms/step\n",
            "Epoch 11/200\n",
            "750/750 - 3s - loss: 0.5960 - accuracy: 0.7787 - val_loss: 0.5065 - val_accuracy: 0.8153 - 3s/epoch - 4ms/step\n",
            "Epoch 12/200\n",
            "750/750 - 3s - loss: 0.5831 - accuracy: 0.7832 - val_loss: 0.5455 - val_accuracy: 0.8027 - 3s/epoch - 4ms/step\n",
            "Epoch 13/200\n",
            "750/750 - 3s - loss: 0.5912 - accuracy: 0.7792 - val_loss: 0.5123 - val_accuracy: 0.8117 - 3s/epoch - 4ms/step\n",
            "Epoch 14/200\n",
            "750/750 - 3s - loss: 0.5720 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.8122 - 3s/epoch - 4ms/step\n",
            "Epoch 15/200\n",
            "750/750 - 3s - loss: 0.5702 - accuracy: 0.7854 - val_loss: 0.4988 - val_accuracy: 0.8163 - 3s/epoch - 4ms/step\n",
            "Epoch 16/200\n",
            "750/750 - 3s - loss: 0.5605 - accuracy: 0.7866 - val_loss: 0.4971 - val_accuracy: 0.8168 - 3s/epoch - 4ms/step\n",
            "Epoch 17/200\n",
            "750/750 - 3s - loss: 0.5550 - accuracy: 0.7895 - val_loss: 0.5039 - val_accuracy: 0.8171 - 3s/epoch - 4ms/step\n",
            "Epoch 18/200\n",
            "750/750 - 3s - loss: 0.5662 - accuracy: 0.7860 - val_loss: 0.4861 - val_accuracy: 0.8183 - 3s/epoch - 4ms/step\n",
            "Epoch 19/200\n",
            "750/750 - 3s - loss: 0.5553 - accuracy: 0.7901 - val_loss: 0.4936 - val_accuracy: 0.8188 - 3s/epoch - 4ms/step\n",
            "Epoch 20/200\n",
            "750/750 - 3s - loss: 0.5520 - accuracy: 0.7914 - val_loss: 0.5713 - val_accuracy: 0.7761 - 3s/epoch - 4ms/step\n",
            "Epoch 21/200\n",
            "750/750 - 3s - loss: 0.5394 - accuracy: 0.7941 - val_loss: 0.4901 - val_accuracy: 0.8138 - 3s/epoch - 4ms/step\n",
            "Epoch 22/200\n",
            "750/750 - 4s - loss: 0.5577 - accuracy: 0.7890 - val_loss: 0.4936 - val_accuracy: 0.8202 - 4s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "750/750 - 3s - loss: 0.5503 - accuracy: 0.7913 - val_loss: 0.4764 - val_accuracy: 0.8223 - 3s/epoch - 4ms/step\n",
            "Epoch 24/200\n",
            "750/750 - 3s - loss: 0.5322 - accuracy: 0.7981 - val_loss: 0.4898 - val_accuracy: 0.8239 - 3s/epoch - 4ms/step\n",
            "Epoch 25/200\n",
            "750/750 - 3s - loss: 0.5468 - accuracy: 0.7937 - val_loss: 0.4830 - val_accuracy: 0.8251 - 3s/epoch - 4ms/step\n",
            "Epoch 26/200\n",
            "750/750 - 3s - loss: 0.5434 - accuracy: 0.7911 - val_loss: 0.4888 - val_accuracy: 0.8149 - 3s/epoch - 4ms/step\n",
            "Epoch 27/200\n",
            "750/750 - 3s - loss: 0.5397 - accuracy: 0.7935 - val_loss: 0.4838 - val_accuracy: 0.8190 - 3s/epoch - 4ms/step\n",
            "Epoch 28/200\n",
            "750/750 - 3s - loss: 0.5287 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.8203 - 3s/epoch - 4ms/step\n",
            "Epoch 29/200\n",
            "750/750 - 3s - loss: 0.5290 - accuracy: 0.7978 - val_loss: 0.4699 - val_accuracy: 0.8245 - 3s/epoch - 4ms/step\n",
            "Epoch 30/200\n",
            "750/750 - 3s - loss: 0.5238 - accuracy: 0.7980 - val_loss: 0.4772 - val_accuracy: 0.8222 - 3s/epoch - 4ms/step\n",
            "Epoch 31/200\n",
            "750/750 - 3s - loss: 0.5272 - accuracy: 0.7967 - val_loss: 0.5498 - val_accuracy: 0.7611 - 3s/epoch - 4ms/step\n",
            "Epoch 32/200\n",
            "750/750 - 3s - loss: 0.5407 - accuracy: 0.7890 - val_loss: 0.5447 - val_accuracy: 0.7782 - 3s/epoch - 4ms/step\n",
            "Epoch 33/200\n",
            "750/750 - 3s - loss: 0.5494 - accuracy: 0.7756 - val_loss: 0.4942 - val_accuracy: 0.8173 - 3s/epoch - 4ms/step\n",
            "Epoch 34/200\n",
            "750/750 - 3s - loss: 0.5237 - accuracy: 0.7944 - val_loss: 0.4759 - val_accuracy: 0.8231 - 3s/epoch - 4ms/step\n",
            "Epoch 35/200\n",
            "750/750 - 3s - loss: 0.5276 - accuracy: 0.7961 - val_loss: 0.4882 - val_accuracy: 0.8231 - 3s/epoch - 4ms/step\n",
            "Epoch 36/200\n",
            "750/750 - 3s - loss: 0.5228 - accuracy: 0.7973 - val_loss: 0.4934 - val_accuracy: 0.8197 - 3s/epoch - 4ms/step\n",
            "Epoch 37/200\n",
            "750/750 - 3s - loss: 0.5219 - accuracy: 0.7980 - val_loss: 0.5478 - val_accuracy: 0.7753 - 3s/epoch - 4ms/step\n",
            "Epoch 38/200\n",
            "750/750 - 3s - loss: 0.5162 - accuracy: 0.7969 - val_loss: 0.4840 - val_accuracy: 0.8231 - 3s/epoch - 4ms/step\n",
            "Epoch 39/200\n",
            "750/750 - 3s - loss: 0.5136 - accuracy: 0.7954 - val_loss: 0.5166 - val_accuracy: 0.7812 - 3s/epoch - 4ms/step\n",
            "Epoch 40/200\n",
            "750/750 - 3s - loss: 0.5136 - accuracy: 0.7957 - val_loss: 0.5160 - val_accuracy: 0.7717 - 3s/epoch - 4ms/step\n",
            "Epoch 41/200\n",
            "750/750 - 3s - loss: 0.5140 - accuracy: 0.7979 - val_loss: 0.4940 - val_accuracy: 0.8182 - 3s/epoch - 4ms/step\n",
            "Epoch 42/200\n",
            "750/750 - 3s - loss: 0.5158 - accuracy: 0.7923 - val_loss: 0.5450 - val_accuracy: 0.7725 - 3s/epoch - 4ms/step\n",
            "Epoch 43/200\n",
            "750/750 - 3s - loss: 0.5461 - accuracy: 0.7730 - val_loss: 0.5019 - val_accuracy: 0.8113 - 3s/epoch - 4ms/step\n",
            "Epoch 44/200\n",
            "750/750 - 4s - loss: 0.5030 - accuracy: 0.8046 - val_loss: 0.4883 - val_accuracy: 0.8180 - 4s/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "750/750 - 3s - loss: 0.5079 - accuracy: 0.7990 - val_loss: 0.5148 - val_accuracy: 0.8072 - 3s/epoch - 4ms/step\n",
            "Epoch 46/200\n",
            "750/750 - 3s - loss: 0.4997 - accuracy: 0.8024 - val_loss: 0.4714 - val_accuracy: 0.8127 - 3s/epoch - 4ms/step\n",
            "Epoch 47/200\n",
            "750/750 - 3s - loss: 0.5039 - accuracy: 0.8009 - val_loss: 0.4825 - val_accuracy: 0.8156 - 3s/epoch - 4ms/step\n",
            "Epoch 48/200\n",
            "750/750 - 3s - loss: 0.5012 - accuracy: 0.8010 - val_loss: 0.4734 - val_accuracy: 0.8217 - 3s/epoch - 4ms/step\n",
            "Epoch 49/200\n",
            "750/750 - 3s - loss: 0.4958 - accuracy: 0.8053 - val_loss: 0.5068 - val_accuracy: 0.8164 - 3s/epoch - 4ms/step\n",
            "Epoch 50/200\n",
            "750/750 - 3s - loss: 0.5002 - accuracy: 0.8014 - val_loss: 0.4898 - val_accuracy: 0.8012 - 3s/epoch - 4ms/step\n",
            "Epoch 51/200\n",
            "750/750 - 3s - loss: 0.4951 - accuracy: 0.8059 - val_loss: 0.4717 - val_accuracy: 0.8227 - 3s/epoch - 4ms/step\n",
            "Epoch 52/200\n",
            "750/750 - 3s - loss: 0.4947 - accuracy: 0.8014 - val_loss: 0.4827 - val_accuracy: 0.8223 - 3s/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "750/750 - 3s - loss: 0.4948 - accuracy: 0.8030 - val_loss: 0.5026 - val_accuracy: 0.8271 - 3s/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "750/750 - 3s - loss: 0.5134 - accuracy: 0.7942 - val_loss: 0.4957 - val_accuracy: 0.7912 - 3s/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "750/750 - 3s - loss: 0.4937 - accuracy: 0.8014 - val_loss: 0.4743 - val_accuracy: 0.8235 - 3s/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "750/750 - 3s - loss: 0.4952 - accuracy: 0.8070 - val_loss: 0.5030 - val_accuracy: 0.8153 - 3s/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "750/750 - 3s - loss: 0.4994 - accuracy: 0.8000 - val_loss: 0.4875 - val_accuracy: 0.8164 - 3s/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "750/750 - 3s - loss: 0.4950 - accuracy: 0.8051 - val_loss: 0.4901 - val_accuracy: 0.8117 - 3s/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "750/750 - 3s - loss: 0.4951 - accuracy: 0.8048 - val_loss: 0.4910 - val_accuracy: 0.8161 - 3s/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "750/750 - 3s - loss: 0.4916 - accuracy: 0.8073 - val_loss: 0.4915 - val_accuracy: 0.8229 - 3s/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "750/750 - 3s - loss: 0.4840 - accuracy: 0.8056 - val_loss: 0.4772 - val_accuracy: 0.8274 - 3s/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "750/750 - 3s - loss: 0.4969 - accuracy: 0.8026 - val_loss: 0.4883 - val_accuracy: 0.8200 - 3s/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "750/750 - 3s - loss: 0.4887 - accuracy: 0.8086 - val_loss: 0.4917 - val_accuracy: 0.8207 - 3s/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "750/750 - 3s - loss: 0.5033 - accuracy: 0.8016 - val_loss: 0.4972 - val_accuracy: 0.8148 - 3s/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "750/750 - 3s - loss: 0.5088 - accuracy: 0.8006 - val_loss: 0.5010 - val_accuracy: 0.7983 - 3s/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "750/750 - 3s - loss: 0.4859 - accuracy: 0.8068 - val_loss: 0.4837 - val_accuracy: 0.8119 - 3s/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "750/750 - 3s - loss: 0.4979 - accuracy: 0.8041 - val_loss: 0.4797 - val_accuracy: 0.8203 - 3s/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "750/750 - 3s - loss: 0.4866 - accuracy: 0.8093 - val_loss: 0.5005 - val_accuracy: 0.8131 - 3s/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "750/750 - 3s - loss: 0.4993 - accuracy: 0.8028 - val_loss: 0.4874 - val_accuracy: 0.8235 - 3s/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "750/750 - 3s - loss: 0.4875 - accuracy: 0.8073 - val_loss: 0.5018 - val_accuracy: 0.8266 - 3s/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "750/750 - 3s - loss: 0.4795 - accuracy: 0.8147 - val_loss: 0.4805 - val_accuracy: 0.8252 - 3s/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "750/750 - 3s - loss: 0.4874 - accuracy: 0.8078 - val_loss: 0.4797 - val_accuracy: 0.8243 - 3s/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "750/750 - 3s - loss: 0.4827 - accuracy: 0.8077 - val_loss: 0.4717 - val_accuracy: 0.8185 - 3s/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "750/750 - 3s - loss: 0.4880 - accuracy: 0.8065 - val_loss: 0.5379 - val_accuracy: 0.8129 - 3s/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "750/750 - 3s - loss: 0.5189 - accuracy: 0.7996 - val_loss: 0.5140 - val_accuracy: 0.8130 - 3s/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "750/750 - 3s - loss: 0.4981 - accuracy: 0.8043 - val_loss: 0.4983 - val_accuracy: 0.8217 - 3s/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "750/750 - 3s - loss: 0.4806 - accuracy: 0.8105 - val_loss: 0.4986 - val_accuracy: 0.8164 - 3s/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "750/750 - 3s - loss: 0.4865 - accuracy: 0.8042 - val_loss: 0.5054 - val_accuracy: 0.8153 - 3s/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "750/750 - 3s - loss: 0.4868 - accuracy: 0.8079 - val_loss: 0.4916 - val_accuracy: 0.8175 - 3s/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "750/750 - 3s - loss: 0.5001 - accuracy: 0.8030 - val_loss: 0.5145 - val_accuracy: 0.8133 - 3s/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "750/750 - 3s - loss: 0.4790 - accuracy: 0.8084 - val_loss: 0.5345 - val_accuracy: 0.7913 - 3s/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "750/750 - 3s - loss: 0.4973 - accuracy: 0.8051 - val_loss: 0.5558 - val_accuracy: 0.7683 - 3s/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "750/750 - 3s - loss: 0.5140 - accuracy: 0.7882 - val_loss: 0.4923 - val_accuracy: 0.8135 - 3s/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "750/750 - 3s - loss: 0.5071 - accuracy: 0.7983 - val_loss: 0.5091 - val_accuracy: 0.8150 - 3s/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "750/750 - 3s - loss: 0.4924 - accuracy: 0.8047 - val_loss: 0.4912 - val_accuracy: 0.8161 - 3s/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "750/750 - 3s - loss: 0.5058 - accuracy: 0.7785 - val_loss: 0.5160 - val_accuracy: 0.8011 - 3s/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "750/750 - 3s - loss: 0.4960 - accuracy: 0.7994 - val_loss: 0.4885 - val_accuracy: 0.8259 - 3s/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "750/750 - 3s - loss: 0.4874 - accuracy: 0.8066 - val_loss: 0.4864 - val_accuracy: 0.8257 - 3s/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "750/750 - 3s - loss: 0.4801 - accuracy: 0.8090 - val_loss: 0.4786 - val_accuracy: 0.8237 - 3s/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "750/750 - 3s - loss: 0.4788 - accuracy: 0.8089 - val_loss: 0.5179 - val_accuracy: 0.8157 - 3s/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "750/750 - 3s - loss: 0.4857 - accuracy: 0.8071 - val_loss: 0.5117 - val_accuracy: 0.8136 - 3s/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "750/750 - 3s - loss: 0.4766 - accuracy: 0.8093 - val_loss: 0.4953 - val_accuracy: 0.8231 - 3s/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "750/750 - 3s - loss: 0.4909 - accuracy: 0.8031 - val_loss: 0.4986 - val_accuracy: 0.8151 - 3s/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "750/750 - 3s - loss: 0.5050 - accuracy: 0.7984 - val_loss: 0.5344 - val_accuracy: 0.8117 - 3s/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "750/750 - 3s - loss: 0.4855 - accuracy: 0.8097 - val_loss: 0.4956 - val_accuracy: 0.8152 - 3s/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "750/750 - 3s - loss: 0.4850 - accuracy: 0.8080 - val_loss: 0.5146 - val_accuracy: 0.8288 - 3s/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "750/750 - 3s - loss: 0.4866 - accuracy: 0.8050 - val_loss: 0.5009 - val_accuracy: 0.8229 - 3s/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "750/750 - 3s - loss: 0.4756 - accuracy: 0.8124 - val_loss: 0.5131 - val_accuracy: 0.8169 - 3s/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "750/750 - 3s - loss: 0.4938 - accuracy: 0.8017 - val_loss: 0.5570 - val_accuracy: 0.7879 - 3s/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "750/750 - 3s - loss: 0.5130 - accuracy: 0.7802 - val_loss: 0.4952 - val_accuracy: 0.8259 - 3s/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "750/750 - 3s - loss: 0.4725 - accuracy: 0.8103 - val_loss: 0.5453 - val_accuracy: 0.7663 - 3s/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "750/750 - 3s - loss: 0.5285 - accuracy: 0.7712 - val_loss: 0.5404 - val_accuracy: 0.7828 - 3s/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "750/750 - 3s - loss: 0.5165 - accuracy: 0.7741 - val_loss: 0.5672 - val_accuracy: 0.7808 - 3s/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "750/750 - 3s - loss: 0.5191 - accuracy: 0.7741 - val_loss: 0.5993 - val_accuracy: 0.8077 - 3s/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "750/750 - 3s - loss: 0.4979 - accuracy: 0.8015 - val_loss: 0.5014 - val_accuracy: 0.8229 - 3s/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "750/750 - 3s - loss: 0.4925 - accuracy: 0.8043 - val_loss: 0.5067 - val_accuracy: 0.8040 - 3s/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "750/750 - 3s - loss: 0.4812 - accuracy: 0.8109 - val_loss: 0.4857 - val_accuracy: 0.8248 - 3s/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "750/750 - 3s - loss: 0.4972 - accuracy: 0.8013 - val_loss: 0.5042 - val_accuracy: 0.7897 - 3s/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "750/750 - 3s - loss: 0.4914 - accuracy: 0.7929 - val_loss: 0.5352 - val_accuracy: 0.7868 - 3s/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "750/750 - 3s - loss: 0.5080 - accuracy: 0.7832 - val_loss: 0.5012 - val_accuracy: 0.8196 - 3s/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "750/750 - 3s - loss: 0.4875 - accuracy: 0.8090 - val_loss: 0.5042 - val_accuracy: 0.8245 - 3s/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "750/750 - 3s - loss: 0.4839 - accuracy: 0.8090 - val_loss: 0.4991 - val_accuracy: 0.8237 - 3s/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "750/750 - 3s - loss: 0.4846 - accuracy: 0.8052 - val_loss: 0.6234 - val_accuracy: 0.7551 - 3s/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "750/750 - 3s - loss: 0.5227 - accuracy: 0.7929 - val_loss: 0.4986 - val_accuracy: 0.8208 - 3s/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "750/750 - 3s - loss: 0.4833 - accuracy: 0.8113 - val_loss: 0.4941 - val_accuracy: 0.8250 - 3s/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "750/750 - 3s - loss: 0.4690 - accuracy: 0.8159 - val_loss: 0.4925 - val_accuracy: 0.8311 - 3s/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "750/750 - 3s - loss: 0.5106 - accuracy: 0.7968 - val_loss: 0.5523 - val_accuracy: 0.7942 - 3s/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "750/750 - 3s - loss: 0.5447 - accuracy: 0.7771 - val_loss: 0.5508 - val_accuracy: 0.7941 - 3s/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "750/750 - 3s - loss: 0.5136 - accuracy: 0.7896 - val_loss: 0.5327 - val_accuracy: 0.8043 - 3s/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "750/750 - 3s - loss: 0.4878 - accuracy: 0.8042 - val_loss: 0.4944 - val_accuracy: 0.8222 - 3s/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "750/750 - 3s - loss: 0.4680 - accuracy: 0.8138 - val_loss: 0.4915 - val_accuracy: 0.8296 - 3s/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "750/750 - 3s - loss: 0.4645 - accuracy: 0.8153 - val_loss: 0.5169 - val_accuracy: 0.8270 - 3s/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "750/750 - 3s - loss: 0.4624 - accuracy: 0.8152 - val_loss: 0.5016 - val_accuracy: 0.8238 - 3s/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "750/750 - 3s - loss: 0.4700 - accuracy: 0.8129 - val_loss: 0.5213 - val_accuracy: 0.8148 - 3s/epoch - 4ms/step\n",
            "Epoch 125/200\n",
            "750/750 - 3s - loss: 0.4907 - accuracy: 0.8081 - val_loss: 0.4852 - val_accuracy: 0.8321 - 3s/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "750/750 - 3s - loss: 0.4723 - accuracy: 0.8143 - val_loss: 0.4984 - val_accuracy: 0.8291 - 3s/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "750/750 - 3s - loss: 0.4686 - accuracy: 0.8155 - val_loss: 0.4882 - val_accuracy: 0.8265 - 3s/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "750/750 - 3s - loss: 0.5062 - accuracy: 0.7908 - val_loss: 0.5027 - val_accuracy: 0.8193 - 3s/epoch - 4ms/step\n",
            "Epoch 129/200\n",
            "750/750 - 3s - loss: 0.4805 - accuracy: 0.8069 - val_loss: 0.5034 - val_accuracy: 0.8003 - 3s/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "750/750 - 3s - loss: 0.5006 - accuracy: 0.7828 - val_loss: 0.5283 - val_accuracy: 0.7944 - 3s/epoch - 4ms/step\n",
            "Epoch 131/200\n",
            "750/750 - 3s - loss: 0.4803 - accuracy: 0.8111 - val_loss: 0.5392 - val_accuracy: 0.8108 - 3s/epoch - 4ms/step\n",
            "Epoch 132/200\n",
            "750/750 - 3s - loss: 0.4834 - accuracy: 0.8012 - val_loss: 0.5175 - val_accuracy: 0.8094 - 3s/epoch - 4ms/step\n",
            "Epoch 133/200\n",
            "750/750 - 3s - loss: 0.4947 - accuracy: 0.7986 - val_loss: 0.4966 - val_accuracy: 0.8265 - 3s/epoch - 4ms/step\n",
            "Epoch 134/200\n",
            "750/750 - 3s - loss: 0.4841 - accuracy: 0.8023 - val_loss: 0.5008 - val_accuracy: 0.8214 - 3s/epoch - 4ms/step\n",
            "Epoch 135/200\n",
            "750/750 - 3s - loss: 0.4945 - accuracy: 0.8083 - val_loss: 0.5174 - val_accuracy: 0.8247 - 3s/epoch - 4ms/step\n",
            "Epoch 136/200\n",
            "750/750 - 3s - loss: 0.4852 - accuracy: 0.8095 - val_loss: 0.5051 - val_accuracy: 0.8271 - 3s/epoch - 4ms/step\n",
            "Epoch 137/200\n",
            "750/750 - 3s - loss: 0.4774 - accuracy: 0.8072 - val_loss: 0.5229 - val_accuracy: 0.8177 - 3s/epoch - 4ms/step\n",
            "Epoch 138/200\n",
            "750/750 - 3s - loss: 0.4731 - accuracy: 0.8133 - val_loss: 0.5042 - val_accuracy: 0.8208 - 3s/epoch - 4ms/step\n",
            "Epoch 139/200\n",
            "750/750 - 3s - loss: 0.4770 - accuracy: 0.8077 - val_loss: 0.5214 - val_accuracy: 0.8084 - 3s/epoch - 4ms/step\n",
            "Epoch 140/200\n",
            "750/750 - 3s - loss: 0.4845 - accuracy: 0.8084 - val_loss: 0.4928 - val_accuracy: 0.8255 - 3s/epoch - 4ms/step\n",
            "Epoch 141/200\n",
            "750/750 - 3s - loss: 0.4622 - accuracy: 0.8161 - val_loss: 0.5210 - val_accuracy: 0.8189 - 3s/epoch - 4ms/step\n",
            "Epoch 142/200\n",
            "750/750 - 3s - loss: 0.4780 - accuracy: 0.8090 - val_loss: 0.5159 - val_accuracy: 0.8191 - 3s/epoch - 4ms/step\n",
            "Epoch 143/200\n",
            "750/750 - 3s - loss: 0.4862 - accuracy: 0.8026 - val_loss: 0.5170 - val_accuracy: 0.7978 - 3s/epoch - 4ms/step\n",
            "Epoch 144/200\n",
            "750/750 - 3s - loss: 0.4781 - accuracy: 0.8099 - val_loss: 0.5130 - val_accuracy: 0.8103 - 3s/epoch - 4ms/step\n",
            "Epoch 145/200\n",
            "750/750 - 3s - loss: 0.4872 - accuracy: 0.8053 - val_loss: 0.5086 - val_accuracy: 0.8242 - 3s/epoch - 4ms/step\n",
            "Epoch 146/200\n",
            "750/750 - 3s - loss: 0.4661 - accuracy: 0.8155 - val_loss: 0.5299 - val_accuracy: 0.8112 - 3s/epoch - 4ms/step\n",
            "Epoch 147/200\n",
            "750/750 - 3s - loss: 0.4803 - accuracy: 0.8109 - val_loss: 0.5206 - val_accuracy: 0.8232 - 3s/epoch - 4ms/step\n",
            "Epoch 148/200\n",
            "750/750 - 3s - loss: 0.4817 - accuracy: 0.8110 - val_loss: 0.5005 - val_accuracy: 0.8233 - 3s/epoch - 4ms/step\n",
            "Epoch 149/200\n",
            "750/750 - 3s - loss: 0.4981 - accuracy: 0.7823 - val_loss: 0.5060 - val_accuracy: 0.8274 - 3s/epoch - 4ms/step\n",
            "Epoch 150/200\n",
            "750/750 - 3s - loss: 0.4643 - accuracy: 0.8145 - val_loss: 0.5034 - val_accuracy: 0.8287 - 3s/epoch - 4ms/step\n",
            "Epoch 151/200\n",
            "750/750 - 3s - loss: 0.4643 - accuracy: 0.8166 - val_loss: 0.5469 - val_accuracy: 0.7968 - 3s/epoch - 4ms/step\n",
            "Epoch 152/200\n",
            "750/750 - 3s - loss: 0.4834 - accuracy: 0.8028 - val_loss: 0.5124 - val_accuracy: 0.8317 - 3s/epoch - 4ms/step\n",
            "Epoch 153/200\n",
            "750/750 - 3s - loss: 0.4688 - accuracy: 0.8140 - val_loss: 0.5098 - val_accuracy: 0.8288 - 3s/epoch - 4ms/step\n",
            "Epoch 154/200\n",
            "750/750 - 3s - loss: 0.4782 - accuracy: 0.8124 - val_loss: 0.5096 - val_accuracy: 0.8120 - 3s/epoch - 4ms/step\n",
            "Epoch 155/200\n",
            "750/750 - 3s - loss: 0.4662 - accuracy: 0.8161 - val_loss: 0.5518 - val_accuracy: 0.8189 - 3s/epoch - 4ms/step\n",
            "Epoch 156/200\n",
            "750/750 - 3s - loss: 0.4878 - accuracy: 0.7881 - val_loss: 0.5066 - val_accuracy: 0.8148 - 3s/epoch - 4ms/step\n",
            "Epoch 157/200\n",
            "750/750 - 3s - loss: 0.4704 - accuracy: 0.8065 - val_loss: 0.5341 - val_accuracy: 0.8151 - 3s/epoch - 4ms/step\n",
            "Epoch 158/200\n",
            "750/750 - 3s - loss: 0.4651 - accuracy: 0.8133 - val_loss: 0.5153 - val_accuracy: 0.8289 - 3s/epoch - 4ms/step\n",
            "Epoch 159/200\n",
            "750/750 - 3s - loss: 0.4881 - accuracy: 0.8056 - val_loss: 0.5097 - val_accuracy: 0.8314 - 3s/epoch - 4ms/step\n",
            "Epoch 160/200\n",
            "750/750 - 3s - loss: 0.4625 - accuracy: 0.8144 - val_loss: 0.5033 - val_accuracy: 0.8272 - 3s/epoch - 4ms/step\n",
            "Epoch 161/200\n",
            "750/750 - 3s - loss: 0.4634 - accuracy: 0.8162 - val_loss: 0.5331 - val_accuracy: 0.8296 - 3s/epoch - 4ms/step\n",
            "Epoch 162/200\n",
            "750/750 - 3s - loss: 0.4689 - accuracy: 0.8150 - val_loss: 0.5507 - val_accuracy: 0.8227 - 3s/epoch - 4ms/step\n",
            "Epoch 163/200\n",
            "750/750 - 3s - loss: 0.4922 - accuracy: 0.8060 - val_loss: 0.5630 - val_accuracy: 0.8157 - 3s/epoch - 4ms/step\n",
            "Epoch 164/200\n",
            "750/750 - 3s - loss: 0.4904 - accuracy: 0.7964 - val_loss: 0.5801 - val_accuracy: 0.7811 - 3s/epoch - 4ms/step\n",
            "Epoch 165/200\n",
            "750/750 - 3s - loss: 0.5112 - accuracy: 0.7796 - val_loss: 0.5494 - val_accuracy: 0.8026 - 3s/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "750/750 - 3s - loss: 0.4788 - accuracy: 0.8121 - val_loss: 0.4911 - val_accuracy: 0.8322 - 3s/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "750/750 - 3s - loss: 0.4594 - accuracy: 0.8154 - val_loss: 0.5368 - val_accuracy: 0.8122 - 3s/epoch - 4ms/step\n",
            "Epoch 168/200\n",
            "750/750 - 3s - loss: 0.4732 - accuracy: 0.8117 - val_loss: 0.5163 - val_accuracy: 0.8288 - 3s/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "750/750 - 3s - loss: 0.4938 - accuracy: 0.8077 - val_loss: 0.4980 - val_accuracy: 0.8305 - 3s/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "750/750 - 3s - loss: 0.4768 - accuracy: 0.8105 - val_loss: 0.5043 - val_accuracy: 0.8314 - 3s/epoch - 4ms/step\n",
            "Epoch 171/200\n",
            "750/750 - 3s - loss: 0.4628 - accuracy: 0.8200 - val_loss: 0.5150 - val_accuracy: 0.8292 - 3s/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "750/750 - 3s - loss: 0.4840 - accuracy: 0.7931 - val_loss: 0.5701 - val_accuracy: 0.8110 - 3s/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "750/750 - 3s - loss: 0.4647 - accuracy: 0.8158 - val_loss: 0.5519 - val_accuracy: 0.8272 - 3s/epoch - 4ms/step\n",
            "Epoch 174/200\n",
            "750/750 - 3s - loss: 0.4683 - accuracy: 0.8151 - val_loss: 0.5606 - val_accuracy: 0.8291 - 3s/epoch - 4ms/step\n",
            "Epoch 175/200\n",
            "750/750 - 3s - loss: 0.4625 - accuracy: 0.8156 - val_loss: 0.5508 - val_accuracy: 0.8229 - 3s/epoch - 4ms/step\n",
            "Epoch 176/200\n",
            "750/750 - 3s - loss: 0.4882 - accuracy: 0.8086 - val_loss: 0.5761 - val_accuracy: 0.8127 - 3s/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "750/750 - 3s - loss: 0.4789 - accuracy: 0.8067 - val_loss: 0.5438 - val_accuracy: 0.8235 - 3s/epoch - 4ms/step\n",
            "Epoch 178/200\n",
            "750/750 - 3s - loss: 0.4689 - accuracy: 0.8104 - val_loss: 0.5202 - val_accuracy: 0.8296 - 3s/epoch - 4ms/step\n",
            "Epoch 179/200\n",
            "750/750 - 3s - loss: 0.4645 - accuracy: 0.8153 - val_loss: 0.5398 - val_accuracy: 0.8207 - 3s/epoch - 4ms/step\n",
            "Epoch 180/200\n",
            "750/750 - 3s - loss: 0.4590 - accuracy: 0.8151 - val_loss: 0.5284 - val_accuracy: 0.8295 - 3s/epoch - 4ms/step\n",
            "Epoch 181/200\n",
            "750/750 - 3s - loss: 0.4803 - accuracy: 0.8118 - val_loss: 0.5266 - val_accuracy: 0.8294 - 3s/epoch - 4ms/step\n",
            "Epoch 182/200\n",
            "750/750 - 3s - loss: 0.4772 - accuracy: 0.8164 - val_loss: 0.5558 - val_accuracy: 0.8267 - 3s/epoch - 4ms/step\n",
            "Epoch 183/200\n",
            "750/750 - 3s - loss: 0.4732 - accuracy: 0.8135 - val_loss: 0.5782 - val_accuracy: 0.7918 - 3s/epoch - 4ms/step\n",
            "Epoch 184/200\n",
            "750/750 - 3s - loss: 0.4969 - accuracy: 0.8049 - val_loss: 0.5489 - val_accuracy: 0.8325 - 3s/epoch - 4ms/step\n",
            "Epoch 185/200\n",
            "750/750 - 3s - loss: 0.4575 - accuracy: 0.8185 - val_loss: 0.5861 - val_accuracy: 0.7857 - 3s/epoch - 4ms/step\n",
            "Epoch 186/200\n",
            "750/750 - 3s - loss: 0.4641 - accuracy: 0.8044 - val_loss: 0.5518 - val_accuracy: 0.8278 - 3s/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "750/750 - 3s - loss: 0.4556 - accuracy: 0.8163 - val_loss: 0.6072 - val_accuracy: 0.8251 - 3s/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "750/750 - 3s - loss: 0.4908 - accuracy: 0.7971 - val_loss: 0.6069 - val_accuracy: 0.7815 - 3s/epoch - 4ms/step\n",
            "Epoch 189/200\n",
            "750/750 - 3s - loss: 0.5036 - accuracy: 0.7806 - val_loss: 0.6296 - val_accuracy: 0.7548 - 3s/epoch - 4ms/step\n",
            "Epoch 190/200\n",
            "750/750 - 3s - loss: 0.5214 - accuracy: 0.7684 - val_loss: 0.6575 - val_accuracy: 0.7802 - 3s/epoch - 4ms/step\n",
            "Epoch 191/200\n",
            "750/750 - 3s - loss: 0.5074 - accuracy: 0.7764 - val_loss: 0.5820 - val_accuracy: 0.7857 - 3s/epoch - 4ms/step\n",
            "Epoch 192/200\n",
            "750/750 - 3s - loss: 0.4930 - accuracy: 0.7795 - val_loss: 0.6127 - val_accuracy: 0.7713 - 3s/epoch - 4ms/step\n",
            "Epoch 193/200\n",
            "750/750 - 3s - loss: 0.5231 - accuracy: 0.7644 - val_loss: 0.6370 - val_accuracy: 0.7638 - 3s/epoch - 4ms/step\n",
            "Epoch 194/200\n",
            "750/750 - 3s - loss: 0.5275 - accuracy: 0.7664 - val_loss: 0.5593 - val_accuracy: 0.7815 - 3s/epoch - 4ms/step\n",
            "Epoch 195/200\n",
            "750/750 - 3s - loss: 0.4885 - accuracy: 0.7885 - val_loss: 0.5498 - val_accuracy: 0.7936 - 3s/epoch - 4ms/step\n",
            "Epoch 196/200\n",
            "750/750 - 3s - loss: 0.4937 - accuracy: 0.8016 - val_loss: 0.5479 - val_accuracy: 0.8223 - 3s/epoch - 4ms/step\n",
            "Epoch 197/200\n",
            "750/750 - 3s - loss: 0.4626 - accuracy: 0.8154 - val_loss: 0.5357 - val_accuracy: 0.8228 - 3s/epoch - 4ms/step\n",
            "Epoch 198/200\n",
            "750/750 - 3s - loss: 0.4544 - accuracy: 0.8161 - val_loss: 0.5291 - val_accuracy: 0.8225 - 3s/epoch - 4ms/step\n",
            "Epoch 199/200\n",
            "750/750 - 3s - loss: 0.4636 - accuracy: 0.8152 - val_loss: 0.5454 - val_accuracy: 0.8216 - 3s/epoch - 4ms/step\n",
            "Epoch 200/200\n",
            "750/750 - 3s - loss: 0.4665 - accuracy: 0.8143 - val_loss: 0.5294 - val_accuracy: 0.8235 - 3s/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train','validation'],loc = 'upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "9_5b1l0JWmk9",
        "outputId": "5d85964c-1130-4777-c425-414391d68f8f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "13pwU7pDYbiR"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/content/checkpoint'\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                            )"
      ],
      "metadata": {
        "id": "PgX6UOOWYneQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}